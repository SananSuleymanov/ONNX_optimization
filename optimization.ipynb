{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMhLevjgxY9CgEnrld8y3MY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SananSuleymanov/ONNX_optimization/blob/main/optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Unw5YY4h1CZh",
        "outputId": "0013647c-9500-479e-edd3-757baff49825"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnxruntime"
      ],
      "metadata": {
        "id": "tyO64euEZ4ba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnxruntime-tools"
      ],
      "metadata": {
        "id": "lgvcODDc2J89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-model-optimization"
      ],
      "metadata": {
        "id": "t9UTpMlf5518"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx-tf"
      ],
      "metadata": {
        "id": "Al2BlwAEmVGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!!pip install onnxoptimizer"
      ],
      "metadata": {
        "id": "C0iEzA3vCmDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Required Dependicies"
      ],
      "metadata": {
        "id": "1V_AI7KbAi_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from onnxruntime.quantization import quantize_dynamic, QuantType, quantize_static, CalibrationDataReader, preprocess\n",
        "from onnxruntime.quantization import QuantType\n",
        "from onnxoptimizer import optimize\n",
        "import onnxruntime\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "import onnx_tf.backend as backend\n",
        "import onnx \n",
        "import numpy as np\n",
        "import time\n",
        "import os"
      ],
      "metadata": {
        "id": "yMc1C3Va6n2_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Inference before optimization"
      ],
      "metadata": {
        "id": "obgn4EwkAspt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jzFcmT810ws8"
      },
      "outputs": [],
      "source": [
        "model_path= '/content/drive/MyDrive/YoloV5_small/small_yolov5.onnx'\n",
        "\n",
        "session= onnxruntime.InferenceSession(model_path)\n",
        "\n",
        "input_name= session.get_inputs()[0].name\n",
        "output_name= session.get_outputs()[0].name"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape= session.get_inputs()[0].shape\n",
        "output_shape= session.get_outputs()[0].shape\n",
        "print('Input shape: {}'.format(input_shape))\n",
        "print('Output shape: {}'.format(output_shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlNf8LlN2nAd",
        "outputId": "3b6fd682-e931-4621-a063-e4f5854f2f16"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: [1, 3, 1024, 1024]\n",
            "Output shape: [1, 73728, 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path= '/content/drive/MyDrive/YoloV5_small/Calibration/Copy of Black__A__Pikl__0_3__L_Keyless__2__11-07-08__0.jpg'\n",
        "\n",
        "inf_image= Image.open(image_path)\n",
        "new_shape=(1024, 1024)\n",
        "\n",
        "#preprocessing of single image for running inference\n",
        "def preprocess(image):\n",
        "  image= image.resize(new_shape)\n",
        "  image= np.array(image, dtype=np.float32)\n",
        "  image= image/255.0\n",
        "  image= np.reshape(image, (image.shape[2], image.shape[0], image.shape[1]))\n",
        "  image= np.expand_dims(image, axis=0)\n",
        "  return image\n"
      ],
      "metadata": {
        "id": "axQik5p85EGn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = preprocess(inf_image)"
      ],
      "metadata": {
        "id": "MdnxyxB6b1LC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time= time.time()\n",
        "output= session.run([output_name], {input_name: input_data} )\n",
        "end_time= time.time()\n",
        "\n",
        "inference_time= (end_time-start_time)\n",
        "print('Inference speed before purning and quantization: {}'.format(inference_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCTwjkNDfADP",
        "outputId": "ff097ef9-4ec7-42b6-ab0f-9b85e517d213"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference speed before purning and quantization: 1.0894615650177002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocess Calibration Data"
      ],
      "metadata": {
        "id": "DIiIWgqgA3H7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_reader(image_path):\n",
        "  images=[]\n",
        "  for filename in os.listdir(image_path):\n",
        "    f= os.path.join(image_path, filename)\n",
        "    image= Image.open(f)\n",
        "    image= image.resize(new_shape)\n",
        "    image= np.array(image, dtype=np.float32)\n",
        "    image= image/255.0\n",
        "    image= np.reshape(image, (image.shape[2], image.shape[0], image.shape[1]))\n",
        "    image= np.expand_dims(image, axis=0)\n",
        "    images.append(image)\n",
        "  images= np.concatenate(\n",
        "        np.expand_dims(images, axis=0), axis=0)\n",
        "  return images"
      ],
      "metadata": {
        "id": "YKzszYn0TPeZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calib_image=data_reader('/content/drive/MyDrive/YoloV5_small/Calibration')"
      ],
      "metadata": {
        "id": "st0oKlymU1F6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Calibration dataset size: {}'.format(calib_image.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgMI5IBVVUqV",
        "outputId": "3edb561b-ef54-4db4-db2e-a953476391ee"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calibration dataset size: (56, 1, 3, 1024, 1024)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Static Quantization"
      ],
      "metadata": {
        "id": "UtdoDlvHAWu0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I couldn't understand the problem but runtime of quantize_static() function took long time and I couldn't finish it successfully."
      ],
      "metadata": {
        "id": "uwj8N4nBA9UB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from onnxruntime.quantization import quantize_static, CalibrationDataReader, preprocess\n",
        "from onnxruntime.quantization import QuantType\n",
        "\n",
        "\n",
        "quant_model_path = '/content/drive/MyDrive/YoloV5_small/small_yolov5.quant.onnx'\n",
        "class DataReader(CalibrationDataReader):\n",
        "  def __init__(self, calibration_images):\n",
        "    self.images=calibration_images\n",
        "    self.enum_data_dicts = []\n",
        "  \n",
        "  def get_next(self):\n",
        "      self.datasize = len(self.images)\n",
        "      self.enum_data_dicts = iter([{input_name: data} for data in self.images])\n",
        "      return next(self.enum_data_dicts, None) \n",
        "\n",
        "dr= DataReader(calib_image)\n",
        "quantize_static(model_path,\n",
        "                quant_model_path,\n",
        "                dr)\n"
      ],
      "metadata": {
        "id": "LR1zsxdWjCOH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "0481e367-198b-4eef-9a74-e89a6da05e3c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Please consider pre-processing before quantization. See https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-7782b45d03d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mdr\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mDataReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalib_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m quantize_static(model_path,\n\u001b[0m\u001b[1;32m     18\u001b[0m                 \u001b[0mquant_model_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 dr)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/onnxruntime/quantization/quantize.py\u001b[0m in \u001b[0;36mquantize_static\u001b[0;34m(model_input, model_output, calibration_data_reader, quant_format, op_types_to_quantize, per_channel, reduce_range, activation_type, weight_type, nodes_to_quantize, nodes_to_exclude, optimize_model, use_external_data_format, calibrate_method, extra_options)\u001b[0m\n\u001b[1;32m    365\u001b[0m             \u001b[0mextra_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcalib_extra_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         )\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mcalibrator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalibration_data_reader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m         \u001b[0mtensors_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalibrator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mcalibrator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/onnxruntime/quantization/calibrate.py\u001b[0m in \u001b[0;36mcollect_data\u001b[0;34m(self, data_reader)\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_outputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0moutput_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_meta\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_feed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPFail\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_fallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Save ONNX model as TF model"
      ],
      "metadata": {
        "id": "xY0LjBUSB3Uz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "onnx_model = onnx.load(model_path)\n",
        "\n",
        "# Convert ONNX model to TensorFlow format\n",
        "tf_model = backend.prepare(onnx_model)\n",
        "tf_model.export_graph(\"model_1/\") \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVXfsu4XTqDN",
        "outputId": "65da0ac1-7cf0-48d1-8bc0-6f8af980eb32"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "WARNING:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "converter= tf.lite.TFLiteConverter.from_saved_model('model_1/')\n",
        "converter.optimizations= [tf.lite.Optimize.DEFAULT]\n",
        "tflite_quant_model= converter.convert() "
      ],
      "metadata": {
        "id": "wYTnyD_raHGL"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('model_1/model.tflite', 'wb') as f:\n",
        "  f.write(tflite_quant_model)"
      ],
      "metadata": {
        "id": "2Y0X07sEyS3O"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interpreter = tf.lite.Interpreter(model_path='/content/model_1/model.tflite')\n",
        "\n",
        "# Get input and output tensors.\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "#preprocess image\n",
        "image= Image.open('/content/drive/MyDrive/YoloV5_small/Calibration/Copy of Black__A__Pikl__0_3__L_Keyless__2__11-07-08__0.jpg')\n",
        "image= image.resize(new_shape)\n",
        "np_features= np.array(image)\n",
        "np_features= np_features/255.0\n",
        "np_features= np.reshape(np_features, (np_features.shape[2], np_features.shape[0], np_features.shape[1]))\n",
        "input_type = input_details[0]['dtype']\n",
        "\n",
        "if input_type == np.int8:\n",
        "    input_scale, input_zero_point = input_details[0]['quantization']\n",
        "    print(\"Input scale:\", input_scale)\n",
        "    print(\"Input zero point:\", input_zero_point)\n",
        "    print()\n",
        "    np_features = (np_features / input_scale) + input_zero_point\n",
        "    np_features = np.around(np_features)\n",
        "    \n",
        "# Convert features to NumPy array of expected type\n",
        "np_features = np_features.astype(input_type)\n",
        "\n",
        "# Add dimension to input sample (TFLite model expects (# samples, data))\n",
        "np_features = np.expand_dims(np_features, axis=0)\n",
        "\n",
        "interpreter.set_tensor(input_details[0]['index'], np_features)\n",
        "\n",
        "# Run inference\n",
        "start_time2= time.time()\n",
        "interpreter.invoke()\n",
        "end_time2= time.time()\n",
        "\n",
        "inference_time2= (end_time2-start_time2)\n",
        "print('Inference speed after quantization: {}'.format(inference_time2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WphKqq4vLCP4",
        "outputId": "2a4abd04-f4af-4835-ad94-46c27ceb85da"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference speed after quantization: 3.0270984172821045\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dynamic Quantization\n"
      ],
      "metadata": {
        "id": "b5f5xuLY1mD1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model is dynamic quantized and saved as 'model_quant.onnx' file"
      ],
      "metadata": {
        "id": "aVAoC3OACP7i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_quant= 'model_quant.onnx'\n",
        "quantized_model = quantize_dynamic(model_path, model_quant)\n"
      ],
      "metadata": {
        "id": "0uqPp0QqEQqz"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the ONNX model\n",
        "model = onnx.load('/content/model_quant.onnx')\n",
        "\n",
        "# Define the magnitude threshold for pruning weights\n",
        "threshold = 0.5\n",
        "\n",
        "# Prune the model using onnxoptimizer\n",
        "passes = [\"extract_constant_to_initializer\", \"eliminate_unused_initializer\"]\n",
        "optimized_model = optimize(model, passes)\n",
        "\n",
        "# Save the pruned model to a file\n",
        "onnx.save(optimized_model, 'pruned_model.onnx')\n"
      ],
      "metadata": {
        "id": "SwK9nk-N7Lge"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Inference after quantization and pruning"
      ],
      "metadata": {
        "id": "wzmIIbisL8qH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I couldn't run inference in the latest model because of the belowmentioned model"
      ],
      "metadata": {
        "id": "jgqB1oi3NgEa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "session= onnxruntime.InferenceSession('/content/pruned_model.onnx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "vOqd3Ua79mtb",
        "outputId": "743d1267-50a7-48ce-90ac-27135f54da7b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotImplemented",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplemented\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-5e8d9bc70b3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0monnxruntime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInferenceSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/pruned_model.onnx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_bytes, sess_options, providers, provider_options, **kwargs)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_inference_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproviders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprovider_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisabled_optimizers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_fallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py\u001b[0m in \u001b[0;36m_create_inference_session\u001b[0;34m(self, providers, provider_options, disabled_optimizers)\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;31m# initialize the C++ InferenceSession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproviders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprovider_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisabled_optimizers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplemented\u001b[0m: [ONNXRuntimeError] : 9 : NOT_IMPLEMENTED : Could not find an implementation for ConvInteger(10) node with name 'Conv_4_quant'"
          ]
        }
      ]
    }
  ]
}