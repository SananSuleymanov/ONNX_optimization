# ONNX optimization
This repository contains optimization.ipynb Colab notebook in order to optimize ONNX model by pruning and quantization.

pruned_model.onnx is the last model which quantized and then pruned while because of the error related to the converted layer name it was not possible to run inference and check the speed. 
